{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Взболтать но не смешивать, shuffle объектов противопоказан (следующий объект зависит от предыдущего)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "\n",
    "seed = 42\n",
    "CONTEXT_WINDOW = (-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('word2vec/araneum_none_fasttextskipgram_300_5_2018.model')\n",
    "# model = KeyedVectors.load_word2vec_format('araneum_none_fasttextskipgram_300_5_2018.tgz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_-5</th>\n",
       "      <th>Lemma_-5</th>\n",
       "      <th>POS_-5</th>\n",
       "      <th>Target_-5</th>\n",
       "      <th>Text_-4</th>\n",
       "      <th>Lemma_-4</th>\n",
       "      <th>POS_-4</th>\n",
       "      <th>Target_-4</th>\n",
       "      <th>Text_-3</th>\n",
       "      <th>Lemma_-3</th>\n",
       "      <th>...</th>\n",
       "      <th>POS_2</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Lemma_3</th>\n",
       "      <th>POS_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Lemma_4</th>\n",
       "      <th>POS_4</th>\n",
       "      <th>Text_5</th>\n",
       "      <th>Lemma_5</th>\n",
       "      <th>POS_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>...</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>O</td>\n",
       "      <td>александр</td>\n",
       "      <td>александр</td>\n",
       "      <td>...</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>действие</td>\n",
       "      <td>действие</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Text_-5 Lemma_-5 POS_-5 Target_-5     Text_-4    Lemma_-4 POS_-4 Target_-4  \\\n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                    островский  островский   NOUN         O   \n",
       "\n",
       "      Text_-3    Lemma_-3  ...  POS_2      Text_3     Lemma_3 POS_3  \\\n",
       "0                          ...   NOUN           .           .  PNCT   \n",
       "1                          ...   PNCT  невольницы  невольница  NOUN   \n",
       "2                          ...   NOUN          н.          н.  UNKN   \n",
       "3  островский  островский  ...   UNKN  островский  островский  NOUN   \n",
       "4   александр   александр  ...   NOUN           .           .  PNCT   \n",
       "\n",
       "       Text_4     Lemma_4 POS_4      Text_5     Lemma_5 POS_5  \n",
       "0  невольницы  невольница  NOUN          н.          н.  UNKN  \n",
       "1          н.          н.  UNKN  островский  островский  NOUN  \n",
       "2  островский  островский  NOUN           .           .  PNCT  \n",
       "3           .           .  PNCT  невольницы  невольница  NOUN  \n",
       "4  невольницы  невольница  NOUN    действие    действие  NOUN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_data.csv', encoding = 'utf-8-sig', sep = ';',index_col=0)\n",
    "data = data.fillna('')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319803\n"
     ]
    }
   ],
   "source": [
    "all_vectors = []\n",
    "cnt = 0\n",
    "for lemma in data[\"Lemma\"]:\n",
    "    try:\n",
    "        all_vectors.append(vectors.word_vec(lemma))\n",
    "    except KeyError:\n",
    "        cnt += 1\n",
    "        all_vectors.append(np.zeros(shape=(300,)))\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = np.array(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = pd.DataFrame(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv('train_target.csv',encoding = 'utf-8-sig', sep = ';' )\n",
    "y = np.array(target['Target']).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426803, 40), (57354, 40))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве теста - взять несколько текстов\n",
    "test_texts = {'Puzhaeva_Гоголь. Игроки.txt',\n",
    "             'Petrushevskaya_uroki_muzyki_ev_prov.txt',\n",
    "             'Yad_EV_prov.txt'}\n",
    "criterion = data['Text_id'].map(lambda x: x in test_texts)\n",
    "test_indices = data[criterion].index.tolist()\n",
    "X_test = data.loc[test_indices,:]\n",
    "y_test = np.array(target.loc[test_indices,:]).reshape(-1,)\n",
    "X_train = data.drop(test_indices)\n",
    "y_train = np.array(target.drop(test_indices)).reshape(-1,)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_vectors_train = all_vectors.drop(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(data,X_train,X_test,colname):\n",
    "    print(colname)\n",
    "    label_enc = LabelEncoder()\n",
    "    onehot_enc = OneHotEncoder()\n",
    "    if colname == 'Target':\n",
    "        label_data = label_enc.fit_transform(['B','I','L','O','U',''])\n",
    "        cols_to_transform = [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],0)]\n",
    "    else:\n",
    "        label_data = label_enc.fit_transform(list(data[colname].unique())+[''])\n",
    "        cols_to_transform = [colname] + [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],CONTEXT_WINDOW[1]+1) if i]\n",
    "    onehot_enc.fit(label_data.reshape(-1, 1))\n",
    "    count_train = hstack([onehot_enc.transform(label_enc.transform(X_train[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_test = hstack([onehot_enc.transform(label_enc.transform(X_test[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_texts = hstack([onehot_enc.transform(label_enc.transform(data[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    return count_texts,count_train,count_test,label_enc,onehot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS\n",
      "Target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426803, 283)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (without 'Text' and 'Lemma')\n",
    "cols_to_vect = ['POS','Target'] # target is the last one, it is important \n",
    "sparse_data = [vectorize(data,X_train,X_test,x) for x in cols_to_vect]\n",
    "encoders = {cols_to_vect[i]:(x[-2],x[-1]) for i,x in enumerate(sparse_data)}\n",
    "# data_vect = hstack([x[0] for x in sparse_data])\n",
    "train_vect = hstack([x[1] for x in sparse_data])\n",
    "# test_vect = hstack([x[2] for x in sparse_data])\n",
    "train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data\n",
    "del sparse_data\n",
    "# del data_vect\n",
    "# del test_vect\n",
    "del X_train\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_vectors_sparse = csr_matrix(all_vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_vectors_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = hstack((train_vect, all_vectors_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426803, 583)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# кроссвалидация по пяти фолдам\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomLogisticRegression(LogisticRegression):\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        сначала нужно заменить существующие предыдущие таргеты предсказанными моделью\n",
    "        для этого нужно\n",
    "            1. векторизировать предыдущие предсказанные (обученные модельки лежат в encoders)\n",
    "            2. заменить существующие ими\n",
    "        и предсказать по этому измененному объекту\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        for item in X.tocsr():\n",
    "            dense_item = np.asarray(item.todense()).reshape(-1)\n",
    "            prev_pred = predicted[CONTEXT_WINDOW[0]:]\n",
    "            if len(prev_pred) < -CONTEXT_WINDOW[0]:\n",
    "                prev_pred = ['']*(-CONTEXT_WINDOW[0]-len(prev_pred)) + prev_pred\n",
    "            encoded = encoders['Target'][1].transform(encoders['Target'][0].transform(prev_pred).reshape(-1, 1))\n",
    "            encoded = np.asarray(encoded.todense()).reshape(-1)\n",
    "            dense_item[-len(encoded):] = encoded\n",
    "            predicted.append(super().predict([dense_item])[0]) # something like this\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 11.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 17.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 22.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 28.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.990487414568\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.22      0.10      0.14      2139\n",
      "          I       0.86      0.88      0.87      2844\n",
      "          L       0.83      0.81      0.82      2139\n",
      "          O       0.99      1.00      1.00    419119\n",
      "          U       0.31      0.19      0.23       562\n",
      "\n",
      "avg / total       0.99      0.99      0.99    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed)\n",
    "cv_logit = cross_val_predict(logit, train_all, y_train, cv = skf, verbose = 5)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))\n",
    "\n",
    "# это ложь и провокация, сначала нужно убрать из теста проставленные ручками таргеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('results.csv','w',encoding='utf-8-sig') as f:\n",
    "    f.write('true;pred\\n')\n",
    "    f.write('\\n'.join([';'.join(x) for x in zip(y_train,cv_logit)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
