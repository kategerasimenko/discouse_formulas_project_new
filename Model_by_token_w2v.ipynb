{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Взболтать но не смешивать, shuffle объектов противопоказан (следующий объект зависит от предыдущего)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Андрей\\Anaconda3\\envs\\python36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from itertools import chain\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "seed = 42\n",
    "CONTEXT_WINDOW = (-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('word2vec/araneum_none_fasttextskipgram_300_5_2018.model')\n",
    "vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_-5</th>\n",
       "      <th>Lemma_-5</th>\n",
       "      <th>POS_-5</th>\n",
       "      <th>Target_-5</th>\n",
       "      <th>Text_-4</th>\n",
       "      <th>Lemma_-4</th>\n",
       "      <th>POS_-4</th>\n",
       "      <th>Target_-4</th>\n",
       "      <th>Text_-3</th>\n",
       "      <th>Lemma_-3</th>\n",
       "      <th>...</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Lemma_3</th>\n",
       "      <th>POS_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Lemma_4</th>\n",
       "      <th>POS_4</th>\n",
       "      <th>Text_5</th>\n",
       "      <th>Lemma_5</th>\n",
       "      <th>POS_5</th>\n",
       "      <th>First</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>...</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>O</td>\n",
       "      <td>александр</td>\n",
       "      <td>александр</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>действие</td>\n",
       "      <td>действие</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Text_-5 Lemma_-5 POS_-5 Target_-5     Text_-4    Lemma_-4 POS_-4 Target_-4  \\\n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                    островский  островский   NOUN         O   \n",
       "\n",
       "      Text_-3    Lemma_-3  ...       Text_3     Lemma_3 POS_3      Text_4  \\\n",
       "0                          ...            .           .  PNCT  невольницы   \n",
       "1                          ...   невольницы  невольница  NOUN          н.   \n",
       "2                          ...           н.          н.  UNKN  островский   \n",
       "3  островский  островский  ...   островский  островский  NOUN           .   \n",
       "4   александр   александр  ...            .           .  PNCT  невольницы   \n",
       "\n",
       "      Lemma_4 POS_4      Text_5     Lemma_5 POS_5 First  \n",
       "0  невольница  NOUN          н.          н.  UNKN     1  \n",
       "1          н.  UNKN  островский  островский  NOUN     1  \n",
       "2  островский  NOUN           .           .  PNCT     1  \n",
       "3           .  PNCT  невольницы  невольница  NOUN     1  \n",
       "4  невольница  NOUN    действие    действие  NOUN     1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_data.csv', encoding = 'utf-8-sig', sep = ';',index_col=0)\n",
    "data = data.fillna('')\n",
    "data['First'] = np.zeros(len(data),dtype=int)\n",
    "data.loc[data['Word_num'] <= 20,'First'] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'B', 'I', 'L', 'O', 'U']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv('train_target.csv',encoding = 'utf-8-sig', sep = ';' )\n",
    "y = np.array(target['Target']).reshape(-1,)\n",
    "\n",
    "target_labels = ['']+sorted(target['Target'].unique())\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426803, 41), (57354, 41))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве теста - взять несколько текстов\n",
    "test_texts = {'Puzhaeva_Гоголь. Игроки.txt',\n",
    "             'Petrushevskaya_uroki_muzyki_ev_prov.txt',\n",
    "             'Yad_EV_prov.txt'}\n",
    "criterion = data['Text_id'].map(lambda x: x in test_texts)\n",
    "test_indices = data[criterion].index.tolist()\n",
    "X_test = data.loc[test_indices,:]\n",
    "y_test = np.array(target.loc[test_indices,:]).reshape(-1,)\n",
    "X_train = data.drop(test_indices)\n",
    "y_train = np.array(target.drop(test_indices)).reshape(-1,)\n",
    "train_indices = X_train.index\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319803\n"
     ]
    }
   ],
   "source": [
    "all_vectors = []\n",
    "cnt = 0\n",
    "for word in data['Lemma']:\n",
    "    try:\n",
    "        all_vectors.append(vectors.word_vec(word))\n",
    "    except KeyError:\n",
    "        cnt += 1\n",
    "        all_vectors.append(np.zeros(shape=(300,)))\n",
    "print(cnt)\n",
    "all_vectors_sparse = csr_matrix(all_vectors)\n",
    "vectors_train = all_vectors_sparse[train_indices,:]\n",
    "#vectors_test = all_vectors_sparse[test_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "all_vectors_sparse = []\n",
    "w2v_model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(data,X_train,X_test,colname):\n",
    "    print(colname)\n",
    "    label_enc = LabelEncoder()\n",
    "    onehot_enc = OneHotEncoder()\n",
    "    if colname == 'Target':\n",
    "        label_data = label_enc.fit_transform(target_labels)\n",
    "        cols_to_transform = [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],0)]\n",
    "    else:\n",
    "        label_data = label_enc.fit_transform(list(data[colname].unique())+[''])\n",
    "        cols_to_transform = [colname] + [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],CONTEXT_WINDOW[1]+1) if i]\n",
    "    onehot_enc.fit(label_data.reshape(-1, 1))\n",
    "    count_train = hstack([onehot_enc.transform(label_enc.transform(X_train[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_test = hstack([onehot_enc.transform(label_enc.transform(X_test[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_texts = hstack([onehot_enc.transform(label_enc.transform(data[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    return count_texts,count_train,count_test,label_enc,onehot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "POS\n",
      "Target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426803, 482614)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to add df col to sparse matrix: np.array(column)[:,None]\n",
    "\n",
    "cols_to_vect = ['Text','POS','Target'] # target is the last one, it is important\n",
    "sparse_data = [vectorize(data,X_train,X_test,x) for x in cols_to_vect]\n",
    "encoders = {cols_to_vect[i]:(x[-2],x[-1]) for i,x in enumerate(sparse_data)}\n",
    "#data_vect = hstack([x[0] for x in sparse_data])\n",
    "train_vect = hstack([vectors_train]+[x[1] for x in sparse_data])\n",
    "#test_vect = hstack([x[2] for x in sparse_data])\n",
    "train_vect.shape #, train_vect.shape, test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': array([1., 0., 0., 0., 0., 0.]),\n",
       " 'B': array([0., 1., 0., 0., 0., 0.]),\n",
       " 'I': array([0., 0., 1., 0., 0., 0.]),\n",
       " 'L': array([0., 0., 0., 1., 0., 0.]),\n",
       " 'O': array([0., 0., 0., 0., 1., 0.]),\n",
       " 'U': array([0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_onehot = {}\n",
    "for label in target_labels:\n",
    "    encoded = encoders['Target'][1].transform(encoders['Target'][0].transform([label]).reshape(-1, 1))\n",
    "    encoded = np.asarray(encoded.todense()).reshape(-1)\n",
    "    label_onehot[label] = encoded\n",
    "label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "sparse_data = []\n",
    "encoders = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Андрей\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\Андрей\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "select_k = SelectKBest(k=100000)\n",
    "#select_k.fit(data_vect, y)\n",
    "selected_train = select_k.fit_transform(train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426803, 100000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# кроссвалидация по пяти фолдам\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomLogisticRegression(LogisticRegression):\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        сначала нужно заменить существующие предыдущие таргеты предсказанными моделью\n",
    "        для этого нужно\n",
    "            1. векторизировать предыдущие предсказанные (обученные модельки лежат в encoders)\n",
    "            2. заменить существующие ими\n",
    "        и предсказать по этому измененному объекту\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        for item in X.tolil():\n",
    "            prev_pred = predicted[CONTEXT_WINDOW[0]:]\n",
    "            if len(prev_pred) < -CONTEXT_WINDOW[0]:\n",
    "                prev_pred = ['']*(-CONTEXT_WINDOW[0]-len(prev_pred)) + prev_pred\n",
    "            encoded = [y for x in prev_pred for y in label_onehot[x]]\n",
    "            item[0,-len(encoded):] = encoded\n",
    "            predicted.append(super().predict(item)[0]) # something like this\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  9.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 13.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 18.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 22.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.966865275080072\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.28      0.36      0.31      2139\n",
      "          I       0.13      0.23      0.17      2844\n",
      "          L       0.22      0.28      0.25      2139\n",
      "          O       0.99      0.98      0.98    419119\n",
      "          U       0.30      0.61      0.40       562\n",
      "\n",
      "avg / total       0.97      0.97      0.97    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "cv_logit = cross_val_predict(logit, selected_train, y_train, cv = skf, verbose = 5)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправление лейблов\n",
    "Пока не работает нормально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "logit_cv_backup = deepcopy(cv_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B': 2728, 'I': 5247, 'L': 2718, 'O': 415018, 'U': 1092})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(cv_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for predictions correction\n",
    "# features - several previous correct answers, several previous predictions, current prediction\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "pred_matrix = []\n",
    "for i in range(len(cv_logit)):\n",
    "    prev_target = y_train[max(0,i+CONTEXT_WINDOW[0]):i]\n",
    "    prev_pred = cv_logit[max(0,i+CONTEXT_WINDOW[0]):i]\n",
    "    if len(prev_target) < -CONTEXT_WINDOW[0]:\n",
    "        prev_target = ['']*(-CONTEXT_WINDOW[0]-len(prev_target)) + list(prev_target)\n",
    "        prev_pred = ['']*(-CONTEXT_WINDOW[0]-len(prev_pred)) + list(prev_pred)\n",
    "    pred_matrix.append([y for x in prev_pred for y in label_onehot[x]]+list(label_onehot[cv_logit[i]]) +\\\n",
    "                       [y for x in prev_target for y in label_onehot[x]])\n",
    "pred_matrix = lil_matrix(pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9598948460999571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.17      0.35      0.23      2139\n",
      "          I       0.13      0.19      0.15      2844\n",
      "          L       0.13      0.27      0.18      2139\n",
      "          O       0.99      0.97      0.98    419119\n",
      "          U       0.13      0.27      0.18       562\n",
      "\n",
      "avg / total       0.97      0.96      0.97    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit2 = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "cv_logit2 = cross_val_predict(logit2, pred_matrix, y_train, cv = skf, verbose = 5)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit2))\n",
    "print(classification_report(y_train, cv_logit2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_logit = deepcopy(logit_cv_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formula = False\n",
    "for i in range(len(cv_logit)):\n",
    "    if cv_logit[i] == 'B':\n",
    "        formula = True\n",
    "    elif cv_logit[i] == 'O' and formula:\n",
    "        cv_logit[i] = 'I'\n",
    "    elif cv_logit[i] == 'L' and formula:\n",
    "        formula = False\n",
    "\n",
    "\n",
    "for i in range(len(cv_logit)):\n",
    "    if i > 0 and i < len(cv_logit)-1:\n",
    "        if (cv_logit[i-1] == 'I' or cv_logit[i-1] == 'B') and cv_logit[i+1] == 'O':\n",
    "            cv_logit[i] = 'L'\n",
    "        elif cv_logit[i-1] == 'O' and (cv_logit[i+1] == 'I' or cv_logit[i-1] == 'B') and cv_logit[i] == 'I':\n",
    "            cv_logit[i] = 'B'\n",
    "        elif cv_logit[i-1] == 'O' and cv_logit[i+1] == 'O' and cv_logit[i] != 'O':\n",
    "            cv_logit[i] = 'U'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9545223440322584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.29      0.37      0.32      2139\n",
      "          I       0.07      0.28      0.12      2844\n",
      "          L       0.23      0.30      0.26      2139\n",
      "          O       0.99      0.97      0.98    419119\n",
      "          U       0.34      0.73      0.46       562\n",
      "\n",
      "avg / total       0.97      0.95      0.96    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrected = cv_logit2 != cv_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('results.csv','w',encoding='utf-8-sig') as f:\n",
    "    f.write('true;pred;pred_corr;corr\\n')\n",
    "    f.write('\\n'.join([';'.join(x) for x in zip(y_train,logit_cv_backup,cv_logit2,[str(x) for x in corrected])]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
