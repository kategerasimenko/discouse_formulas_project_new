{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Взболтать но не смешивать, shuffle объектов противопоказан (следующий объект зависит от предыдущего)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "from itertools import chain\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "seed = 42\n",
    "CONTEXT_WINDOW = (-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('word2vec/araneum_none_fasttextskipgram_300_5_2018.model')\n",
    "vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_-5</th>\n",
       "      <th>Lemma_-5</th>\n",
       "      <th>POS_-5</th>\n",
       "      <th>Target_-5</th>\n",
       "      <th>Text_-4</th>\n",
       "      <th>Lemma_-4</th>\n",
       "      <th>POS_-4</th>\n",
       "      <th>Target_-4</th>\n",
       "      <th>Text_-3</th>\n",
       "      <th>Lemma_-3</th>\n",
       "      <th>...</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Lemma_3</th>\n",
       "      <th>POS_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Lemma_4</th>\n",
       "      <th>POS_4</th>\n",
       "      <th>Text_5</th>\n",
       "      <th>Lemma_5</th>\n",
       "      <th>POS_5</th>\n",
       "      <th>First</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>...</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>O</td>\n",
       "      <td>александр</td>\n",
       "      <td>александр</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>действие</td>\n",
       "      <td>действие</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Text_-5 Lemma_-5 POS_-5 Target_-5     Text_-4    Lemma_-4 POS_-4 Target_-4  \\\n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                    островский  островский   NOUN         O   \n",
       "\n",
       "      Text_-3    Lemma_-3  ...       Text_3     Lemma_3 POS_3      Text_4  \\\n",
       "0                          ...            .           .  PNCT  невольницы   \n",
       "1                          ...   невольницы  невольница  NOUN          н.   \n",
       "2                          ...           н.          н.  UNKN  островский   \n",
       "3  островский  островский  ...   островский  островский  NOUN           .   \n",
       "4   александр   александр  ...            .           .  PNCT  невольницы   \n",
       "\n",
       "      Lemma_4 POS_4      Text_5     Lemma_5 POS_5 First  \n",
       "0  невольница  NOUN          н.          н.  UNKN     1  \n",
       "1          н.  UNKN  островский  островский  NOUN     1  \n",
       "2  островский  NOUN           .           .  PNCT     1  \n",
       "3           .  PNCT  невольницы  невольница  NOUN     1  \n",
       "4  невольница  NOUN    действие    действие  NOUN     1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_data.csv', encoding = 'utf-8-sig', sep = ';',index_col=0)\n",
    "data = data.fillna('')\n",
    "data['First'] = np.zeros(len(data),dtype=int)\n",
    "data.loc[data['Word_num'] <= 20,'First'] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'B', 'I', 'L', 'O', 'U']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv('train_target.csv',encoding = 'utf-8-sig', sep = ';' )\n",
    "y = np.array(target['Target']).reshape(-1,)\n",
    "\n",
    "target_labels = ['']+sorted(target['Target'].unique())\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426803, 41), (57354, 41))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве теста - взять несколько текстов\n",
    "test_texts = {'Puzhaeva_Гоголь. Игроки.txt',\n",
    "             'Petrushevskaya_uroki_muzyki_ev_prov.txt',\n",
    "             'Yad_EV_prov.txt'}\n",
    "criterion = data['Text_id'].map(lambda x: x in test_texts)\n",
    "test_indices = data[criterion].index.tolist()\n",
    "X_test = data.loc[test_indices,:]\n",
    "y_test = np.array(target.loc[test_indices,:]).reshape(-1,)\n",
    "X_train = data.drop(test_indices)\n",
    "y_train = np.array(target.drop(test_indices)).reshape(-1,)\n",
    "train_indices = X_train.index\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319803\n"
     ]
    }
   ],
   "source": [
    "all_vectors = []\n",
    "cnt = 0\n",
    "for word in data['Lemma']:\n",
    "    try:\n",
    "        all_vectors.append(vectors.word_vec(word))\n",
    "    except KeyError:\n",
    "        cnt += 1\n",
    "        all_vectors.append(np.zeros(shape=(300,)))\n",
    "print(cnt)\n",
    "all_vectors_sparse = csr_matrix(all_vectors)\n",
    "vectors_train = all_vectors_sparse[train_indices,:]\n",
    "vectors_test = all_vectors_sparse[test_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "all_vectors_sparse = []\n",
    "w2v_model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(data,X_train,X_test,colname):\n",
    "    print(colname)\n",
    "    label_enc = LabelEncoder()\n",
    "    onehot_enc = OneHotEncoder()\n",
    "    if colname == 'Target':\n",
    "        label_data = label_enc.fit_transform(target_labels)\n",
    "        cols_to_transform = [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],0)]\n",
    "    else:\n",
    "        label_data = label_enc.fit_transform(list(data[colname].unique())+[''])\n",
    "        cols_to_transform = [colname] + [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],CONTEXT_WINDOW[1]+1) if i]\n",
    "    onehot_enc.fit(label_data.reshape(-1, 1))\n",
    "    count_train = hstack([onehot_enc.transform(label_enc.transform(X_train[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_test = hstack([onehot_enc.transform(label_enc.transform(X_test[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_texts = hstack([onehot_enc.transform(label_enc.transform(data[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    return count_texts,count_train,count_test,label_enc,onehot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "POS\n",
      "Target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426803, 482614)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to add df col to sparse matrix: np.array(column)[:,None]\n",
    "\n",
    "cols_to_vect = ['Text','POS','Target'] # target is the last one, it is important\n",
    "sparse_data = [vectorize(data,X_train,X_test,x) for x in cols_to_vect]\n",
    "encoders = {cols_to_vect[i]:(x[-2],x[-1]) for i,x in enumerate(sparse_data)}\n",
    "#data_vect = hstack([x[0] for x in sparse_data])\n",
    "train_vect = hstack([vectors_train]+[x[1] for x in sparse_data])\n",
    "test_vect = hstack([vectors_test]+[x[2] for x in sparse_data])\n",
    "train_vect.shape #, train_vect.shape, test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': array([1., 0., 0., 0., 0., 0.]),\n",
       " 'B': array([0., 1., 0., 0., 0., 0.]),\n",
       " 'I': array([0., 0., 1., 0., 0., 0.]),\n",
       " 'L': array([0., 0., 0., 1., 0., 0.]),\n",
       " 'O': array([0., 0., 0., 0., 1., 0.]),\n",
       " 'U': array([0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_onehot = {}\n",
    "for label in target_labels:\n",
    "    encoded = encoders['Target'][1].transform(encoders['Target'][0].transform([label]).reshape(-1, 1))\n",
    "    encoded = np.asarray(encoded.todense()).reshape(-1)\n",
    "    label_onehot[label] = encoded\n",
    "label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "sparse_data = []\n",
    "encoders = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# норм тема\n",
    "# тут можно использовать обычные модели, потому что делается только фит без предикта\n",
    "# очень долго, лучше грузить из pickle\n",
    "select_model = SelectFromModel(LogisticRegression(penalty='l1',random_state=seed,class_weight='balanced'))\n",
    "selected_train = select_model.fit_transform(train_vect, y_train)\n",
    "\n",
    "with open('select_model.pickle','wb') as f:\n",
    "    pickle.dump(select_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('select_model.pickle','rb') as f:\n",
    "    select_model = pickle.load(f)\n",
    "selected_train = select_model.transform(train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_test = select_model.transform(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ААА НАДО УЧИТЫВАТЬ ТАРГЕТ ПРИ ФИЛЬТРАЦИИ ПРИЗНАКОВ\n",
    "target_in_feats = select_model.get_support()[CONTEXT_WINDOW[0]*len(target_labels):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# кроссвалидация по пяти фолдам\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomLogisticRegression(LogisticRegression):\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        сначала нужно заменить существующие предыдущие таргеты предсказанными моделью\n",
    "        для этого нужно\n",
    "            1. векторизировать предыдущие предсказанные (обученные модельки лежат в encoders)\n",
    "            2. заменить существующие ими\n",
    "        и предсказать по этому измененному объекту\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        for item in X.tolil():\n",
    "            prev_pred = predicted[CONTEXT_WINDOW[0]:]\n",
    "            if len(prev_pred) < -CONTEXT_WINDOW[0]:\n",
    "                prev_pred = ['']*(-CONTEXT_WINDOW[0]-len(prev_pred)) + prev_pred\n",
    "            encoded = np.fromiter((y for x in prev_pred for y in label_onehot[x]),dtype=int)[target_in_feats] # not tested\n",
    "            item[0,-len(encoded):] = encoded\n",
    "            predicted.append(super().predict(item)[0]) # something like this\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  4.4min remaining:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9705601881898674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.31      0.44      0.36      2139\n",
      "          I       0.20      0.26      0.22      2844\n",
      "          L       0.25      0.36      0.29      2139\n",
      "          O       0.99      0.98      0.99    419119\n",
      "          U       0.31      0.69      0.43       562\n",
      "\n",
      "avg / total       0.98      0.97      0.97    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "cv_logit = cross_val_predict(logit, selected_train, y_train, cv = skf, verbose = 5, n_jobs=4)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomLinearSVC(LinearSVC):\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        сначала нужно заменить существующие предыдущие таргеты предсказанными моделью\n",
    "        для этого нужно\n",
    "            1. векторизировать предыдущие предсказанные (обученные модельки лежат в encoders)\n",
    "            2. заменить существующие ими\n",
    "        и предсказать по этому измененному объекту\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        for item in X.tolil():\n",
    "            prev_pred = predicted[CONTEXT_WINDOW[0]:]\n",
    "            if len(prev_pred) < -CONTEXT_WINDOW[0]:\n",
    "                prev_pred = ['']*(-CONTEXT_WINDOW[0]-len(prev_pred)) + prev_pred\n",
    "            encoded = np.fromiter((y for x in prev_pred for y in label_onehot[x]),dtype=int)[target_in_feats] # not tested\n",
    "            item[0,-len(encoded):] = encoded\n",
    "            predicted.append(super().predict(item)[0]) # something like this\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  1.4min remaining:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9762443094355007\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.43      0.30      0.35      2139\n",
      "          I       0.17      0.18      0.18      2844\n",
      "          L       0.35      0.25      0.29      2139\n",
      "          O       0.99      0.99      0.99    419119\n",
      "          U       0.34      0.61      0.44       562\n",
      "\n",
      "avg / total       0.98      0.98      0.98    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = CustomLinearSVC(random_state=seed,class_weight='balanced')\n",
    "cv_svc = cross_val_predict(svc, selected_train, y_train, cv = skf, verbose = 5, n_jobs=4)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_svc))\n",
    "print(classification_report(y_train, cv_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9657914007741396\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.34      0.38      0.36       356\n",
      "          I       0.33      0.22      0.26       792\n",
      "          L       0.31      0.35      0.33       356\n",
      "          O       0.98      0.98      0.98     55845\n",
      "          U       0.08      0.60      0.14         5\n",
      "\n",
      "avg / total       0.96      0.97      0.96     57354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "logit.fit(selected_train, y_train)\n",
    "test_logit = logit.predict(selected_test)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## сделать лейблы бинарными и посмотреть качество "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "test_logit_backup = deepcopy(test_logit)\n",
    "y_test_backup = deepcopy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_logit = deepcopy(test_logit_backup)\n",
    "test_logit = [1 if i != 'O' else 0 for i in test_logit]\n",
    "\n",
    "y_test = deepcopy(y_test_backup)\n",
    "y_test[y_test != 'O'] = 1\n",
    "y_test[y_test == 'O'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.964012972068208\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     55845\n",
      "          1       0.31      0.31      0.31      1509\n",
      "\n",
      "avg / total       0.96      0.96      0.96     57354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(list(y_test), test_logit))\n",
    "print(classification_report(list(y_test), test_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправление лейблов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "logit_cv_backup = deepcopy(cv_logit)\n",
    "cv_logit2 = deepcopy(logit_cv_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_logit = deepcopy(logit_cv_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = False\n",
    "for i in range(len(cv_logit)):\n",
    "    if cv_logit[i] == 'B':\n",
    "        formula = True\n",
    "        b_idx = i\n",
    "        cur_idxs = []\n",
    "    elif cv_logit[i] == 'O' and formula:\n",
    "        cur_idxs.append(i)\n",
    "    elif cv_logit[i] == 'L' and formula:\n",
    "        if len(cur_idxs) < 5:\n",
    "            cv_logit[cur_idxs] = 'I'\n",
    "        else:\n",
    "            cv_logit[b_idx] = 'U'\n",
    "            cv_logit[i] = 'U'\n",
    "        cur_idxs = []\n",
    "        formula = False\n",
    "\n",
    "for i in range(len(cv_logit)):\n",
    "    if i > 0 and i < len(cv_logit)-1:\n",
    "        if (cv_logit[i-1] == 'I' or cv_logit[i-1] == 'B') and cv_logit[i+1] == 'O':\n",
    "            cv_logit[i] = 'L'\n",
    "        elif (cv_logit[i-1] == 'O' or cv_logit[i-1] == 'L') and (cv_logit[i+1] == 'I' or cv_logit[i+1] == 'L') \\\n",
    "             and cv_logit[i] == 'I':\n",
    "            cv_logit[i] = 'B'\n",
    "        elif cv_logit[i-1] == 'O' and cv_logit[i+1] == 'O' and cv_logit[i] != 'O':\n",
    "            cv_logit[i] = 'U'\n",
    "\n",
    "flen = 0\n",
    "for i in range(len(cv_logit)):\n",
    "    if cv_logit[i] != 'O':\n",
    "        flen += 1\n",
    "    if cv_logit[i] == 'O':\n",
    "        if flen > 10:\n",
    "            cv_logit[i-flen:i] = 'O'\n",
    "        if flen:\n",
    "            flen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9726712323952736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.33      0.45      0.38      2139\n",
      "          I       0.27      0.32      0.29      2844\n",
      "          L       0.27      0.37      0.31      2139\n",
      "          O       0.99      0.98      0.99    419119\n",
      "          U       0.36      0.84      0.50       562\n",
      "\n",
      "avg / total       0.98      0.97      0.97    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrected = cv_logit2 != cv_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('results.csv','w',encoding='utf-8-sig') as f:\n",
    "    f.write('true;pred;pred_corr;corr\\n')\n",
    "    f.write('\\n'.join([';'.join(x) for x in zip(y_train,logit_cv_backup,cv_logit,[str(x) for x in corrected])]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
