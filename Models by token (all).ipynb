{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Взболтать но не смешивать, shuffle объектов противопоказан (следующий объект зависит от предыдущего)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, lil_matrix, hstack, vstack\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest\n",
    "from itertools import chain\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "seed = 42\n",
    "CONTEXT_WINDOW = (-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кроссвалидация по пяти фолдам\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression(LogisticRegression):\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        сначала нужно заменить существующие предыдущие таргеты предсказанными моделью\n",
    "        для этого нужно\n",
    "            1. векторизировать предыдущие предсказанные (обученные модельки лежат в encoders)\n",
    "            2. заменить существующие ими\n",
    "        и предсказать по этому измененному объекту\n",
    "        \"\"\"\n",
    "        predicted = []\n",
    "        for item in X.tolil():\n",
    "            prev_pred = predicted[CONTEXT_WINDOW[0]:]\n",
    "            if len(prev_pred) < -CONTEXT_WINDOW[0]:\n",
    "                prev_pred = ['']*(-CONTEXT_WINDOW[0]-len(prev_pred)) + prev_pred\n",
    "            encoded = np.fromiter((y for x in prev_pred for y in label_onehot[x]),dtype=int)[target_in_feats] # not tested\n",
    "            item[0,-len(encoded):] = encoded\n",
    "            predicted.append(super().predict(item)[0]) # something like this\n",
    "        return np.array(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исправление лейблов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_correction(test_logit):\n",
    "    formula = False\n",
    "    for i in range(len(test_logit)):\n",
    "        if test_logit[i] == 'B':\n",
    "            formula = True\n",
    "            b_idx = i\n",
    "            cur_idxs = []\n",
    "        elif test_logit[i] == 'O' and formula:\n",
    "            cur_idxs.append(i)\n",
    "        elif test_logit[i] == 'L' and formula:\n",
    "            if len(cur_idxs) < 5:\n",
    "                test_logit[cur_idxs] = 'I'\n",
    "            else:\n",
    "                test_logit[b_idx] = 'U'\n",
    "                test_logit[i] = 'U'\n",
    "            cur_idxs = []\n",
    "            formula = False\n",
    "\n",
    "    for i in range(len(test_logit)):\n",
    "        if i > 0 and i < len(test_logit)-1:\n",
    "            if (test_logit[i-1] == 'I' or test_logit[i-1] == 'B') and test_logit[i+1] == 'O' and test_logit[i] == 'I':\n",
    "                test_logit[i] = 'L'\n",
    "            elif (test_logit[i-1] == 'O' or test_logit[i-1] == 'L') and (test_logit[i+1] == 'I' or test_logit[i+1] == 'L') \\\n",
    "                 and test_logit[i] == 'I':\n",
    "                test_logit[i] = 'B'\n",
    "            elif test_logit[i-1] == 'O' and test_logit[i+1] == 'O' and test_logit[i] != 'O':\n",
    "                test_logit[i] = 'U'\n",
    "\n",
    "    flen = 0\n",
    "    for i in range(len(test_logit)):\n",
    "        if test_logit[i] != 'O':\n",
    "            flen += 1\n",
    "        if test_logit[i] == 'O':\n",
    "            if flen > 10:\n",
    "                test_logit[i-flen:i] = 'O'\n",
    "            if flen:\n",
    "                flen = 0\n",
    "    return test_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('word2vec/araneum_none_fasttextskipgram_300_5_2018.model')\n",
    "vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_-5</th>\n",
       "      <th>Lemma_-5</th>\n",
       "      <th>POS_-5</th>\n",
       "      <th>Target_-5</th>\n",
       "      <th>Text_-4</th>\n",
       "      <th>Lemma_-4</th>\n",
       "      <th>POS_-4</th>\n",
       "      <th>Target_-4</th>\n",
       "      <th>Text_-3</th>\n",
       "      <th>Lemma_-3</th>\n",
       "      <th>...</th>\n",
       "      <th>Text_3</th>\n",
       "      <th>Lemma_3</th>\n",
       "      <th>POS_3</th>\n",
       "      <th>Text_4</th>\n",
       "      <th>Lemma_4</th>\n",
       "      <th>POS_4</th>\n",
       "      <th>Text_5</th>\n",
       "      <th>Lemma_5</th>\n",
       "      <th>POS_5</th>\n",
       "      <th>First</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>н.</td>\n",
       "      <td>н.</td>\n",
       "      <td>UNKN</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>...</td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>островский</td>\n",
       "      <td>островский</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>O</td>\n",
       "      <td>александр</td>\n",
       "      <td>александр</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PNCT</td>\n",
       "      <td>невольницы</td>\n",
       "      <td>невольница</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>действие</td>\n",
       "      <td>действие</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Text_-5 Lemma_-5 POS_-5 Target_-5     Text_-4    Lemma_-4 POS_-4 Target_-4  \\\n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                    островский  островский   NOUN         O   \n",
       "\n",
       "      Text_-3    Lemma_-3  ...       Text_3     Lemma_3 POS_3      Text_4  \\\n",
       "0                          ...            .           .  PNCT  невольницы   \n",
       "1                          ...   невольницы  невольница  NOUN          н.   \n",
       "2                          ...           н.          н.  UNKN  островский   \n",
       "3  островский  островский  ...   островский  островский  NOUN           .   \n",
       "4   александр   александр  ...            .           .  PNCT  невольницы   \n",
       "\n",
       "      Lemma_4 POS_4      Text_5     Lemma_5 POS_5 First  \n",
       "0  невольница  NOUN          н.          н.  UNKN     1  \n",
       "1          н.  UNKN  островский  островский  NOUN     1  \n",
       "2  островский  NOUN           .           .  PNCT     1  \n",
       "3           .  PNCT  невольницы  невольница  NOUN     1  \n",
       "4  невольница  NOUN    действие    действие  NOUN     1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_data.csv', encoding = 'utf-8-sig', sep = ';',index_col=0)\n",
    "data = data.fillna('')\n",
    "data['First'] = np.zeros(len(data),dtype=int)\n",
    "data.loc[data['Word_num'] <= 20,'First'] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'B', 'I', 'L', 'O', 'U']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv('train_target.csv',encoding = 'utf-8-sig', sep = ';' )\n",
    "y = np.array(target['Target']).reshape(-1,)\n",
    "\n",
    "target_labels = ['']+sorted(target['Target'].unique())\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426803, 41), (57354, 41))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве теста - взять несколько текстов\n",
    "test_texts = {'Puzhaeva_Гоголь. Игроки.txt',\n",
    "             'Petrushevskaya_uroki_muzyki_ev_prov.txt',\n",
    "             'Yad_EV_prov.txt'}\n",
    "criterion = data['Text_id'].map(lambda x: x in test_texts)\n",
    "test_indices = data[criterion].index.tolist()\n",
    "X_test = data.loc[test_indices,:]\n",
    "y_test = np.array(target.loc[test_indices,:]).reshape(-1,)\n",
    "X_train = data.drop(test_indices)\n",
    "y_train = np.array(target.drop(test_indices)).reshape(-1,)\n",
    "train_indices = X_train.index\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319803\n"
     ]
    }
   ],
   "source": [
    "all_vectors = []\n",
    "cnt = 0\n",
    "for word in data['Lemma']:\n",
    "    try:\n",
    "        all_vectors.append(vectors.word_vec(word))\n",
    "    except KeyError:\n",
    "        cnt += 1\n",
    "        all_vectors.append(np.zeros(shape=(300,)))\n",
    "print(cnt)\n",
    "all_vectors_sparse = csr_matrix(all_vectors)\n",
    "vectors_train = all_vectors_sparse[train_indices,:]\n",
    "vectors_test = all_vectors_sparse[test_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "all_vectors_sparse = []\n",
    "w2v_model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data,X_train,X_test,colname):\n",
    "    print(colname)\n",
    "    label_enc = LabelEncoder()\n",
    "    onehot_enc = OneHotEncoder()\n",
    "    if colname == 'Target':\n",
    "        label_data = label_enc.fit_transform(target_labels)\n",
    "        cols_to_transform = [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],0)]\n",
    "    else:\n",
    "        label_data = label_enc.fit_transform(list(data[colname].unique())+[''])\n",
    "        cols_to_transform = [colname] + [colname+'_'+str(i) for i in range(CONTEXT_WINDOW[0],CONTEXT_WINDOW[1]+1) if i]\n",
    "    onehot_enc.fit(label_data.reshape(-1, 1))\n",
    "    count_train = hstack([onehot_enc.transform(label_enc.transform(X_train[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_test = hstack([onehot_enc.transform(label_enc.transform(X_test[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    count_texts = hstack([onehot_enc.transform(label_enc.transform(data[col]).reshape(-1, 1)) for col in cols_to_transform])\n",
    "    return count_texts,count_train,count_test,label_enc,onehot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "POS\n",
      "Target\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((426803, 482614), (57354, 482614))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to add df col to sparse matrix: np.array(column)[:,None]\n",
    "\n",
    "cols_to_vect = ['Text','POS','Target'] # target is the last one, it is important\n",
    "sparse_data = [vectorize(data,X_train,X_test,x) for x in cols_to_vect]\n",
    "encoders = {cols_to_vect[i]:(x[-2],x[-1]) for i,x in enumerate(sparse_data)}\n",
    "train_vect = hstack([vectors_train]+[x[1] for x in sparse_data])\n",
    "test_vect = hstack([vectors_test]+[x[2] for x in sparse_data])\n",
    "train_vect.shape, test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': array([1., 0., 0., 0., 0., 0.]),\n",
       " 'B': array([0., 1., 0., 0., 0., 0.]),\n",
       " 'I': array([0., 0., 1., 0., 0., 0.]),\n",
       " 'L': array([0., 0., 0., 1., 0., 0.]),\n",
       " 'O': array([0., 0., 0., 0., 1., 0.]),\n",
       " 'U': array([0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_onehot = {}\n",
    "for label in target_labels:\n",
    "    encoded = encoders['Target'][1].transform(encoders['Target'][0].transform([label]).reshape(-1, 1))\n",
    "    encoded = np.asarray(encoded.todense()).reshape(-1)\n",
    "    label_onehot[label] = encoded\n",
    "label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sparse_data = []\n",
    "encoders = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All feats without w2v and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_in_feats = [True]*(-CONTEXT_WINDOW[0]*len(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.964361683579175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.37      0.33      0.35       356\n",
      "          I       0.24      0.22      0.23       792\n",
      "          L       0.35      0.31      0.33       356\n",
      "          O       0.98      0.98      0.98     55845\n",
      "          U       0.07      0.40      0.11         5\n",
      "\n",
      "avg / total       0.96      0.96      0.96     57354\n",
      "\n",
      "Accuracy:\n",
      "0.9695923562436796\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.38      0.31      0.34       356\n",
      "          I       0.38      0.18      0.24       792\n",
      "          L       0.35      0.28      0.31       356\n",
      "          O       0.98      0.99      0.98     55845\n",
      "          U       0.07      0.40      0.11         5\n",
      "\n",
      "avg / total       0.96      0.97      0.97     57354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "logit.fit(hstack([x[1] for x in sparse_data]), y_train)\n",
    "test_logit = logit.predict(hstack([x[2] for x in sparse_data]))\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))\n",
    "\n",
    "test_logit = rule_correction(test_logit)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All feats with central w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_in_feats = [True]*(-CONTEXT_WINDOW[0]*len(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9633329846218224\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.37      0.36      0.36       356\n",
      "          I       0.23      0.22      0.23       792\n",
      "          L       0.35      0.33      0.34       356\n",
      "          O       0.98      0.98      0.98     55845\n",
      "          U       0.03      0.20      0.06         5\n",
      "\n",
      "avg / total       0.96      0.96      0.96     57354\n",
      "\n",
      "Accuracy:\n",
      "0.969313387034906\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.38      0.33      0.35       356\n",
      "          I       0.38      0.19      0.25       792\n",
      "          L       0.35      0.30      0.32       356\n",
      "          O       0.98      0.99      0.98     55845\n",
      "          U       0.03      0.20      0.06         5\n",
      "\n",
      "avg / total       0.96      0.97      0.97     57354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "logit.fit(train_vect, y_train)\n",
    "test_logit = logit.predict(test_vect)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))\n",
    "\n",
    "test_logit = rule_correction(test_logit)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All feats with all w2v including context\n",
    "это если только арендовать сервера Пентагона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на это нужно МНОГО RAM (гигов 30, если не больше)\n",
    "all_vectors = lil_matrix((data.shape[0],(CONTEXT_WINDOW[1]-CONTEXT_WINDOW[0]+1)*300))\n",
    "cnt = 0\n",
    "for idx,i in enumerate(range(CONTEXT_WINDOW[0],CONTEXT_WINDOW[1]+1)):\n",
    "    col = 'Lemma_'+str(i) if i else 'Lemma'\n",
    "    for j,word in enumerate(data[col]):\n",
    "        try:\n",
    "            all_vectors[j,idx*300:idx*300+300] = vectors.word_vec(word)\n",
    "        except KeyError:\n",
    "            cnt += 1\n",
    "print(cnt)\n",
    "all_vectors_sparse = csr_matrix(all_vectors)\n",
    "vectors_train = all_vectors_sparse[train_indices,:]\n",
    "vectors_test = all_vectors_sparse[test_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vect = hstack([vectors_train]+[x[1] for x in sparse_data])\n",
    "test_vect = hstack([vectors_test]+[x[2] for x in sparse_data])\n",
    "train_vect.shape, test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_in_feats = [True]*(-CONTEXT_WINDOW[0]*len(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "logit.fit(train_vect, y_train)\n",
    "test_logit = logit.predict(test_vect)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))\n",
    "\n",
    "test_logit = rule_correction(test_logit)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# норм тема\n",
    "# тут можно использовать обычные модели, потому что делается только фит без предикта\n",
    "# очень долго, лучше грузить из pickle\n",
    "select_model = SelectFromModel(LogisticRegression(penalty='l1',random_state=seed,class_weight='balanced'))\n",
    "selected_train = select_model.fit_transform(train_vect, y_train)\n",
    "\n",
    "with open('select_model.pickle','wb') as f:\n",
    "    pickle.dump(select_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('select_model.pickle','rb') as f:\n",
    "    select_model = pickle.load(f)\n",
    "selected_train = select_model.transform(train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_test = select_model.transform(test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426803, 5774), (57354, 5774))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_train.shape, selected_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ААА НАДО УЧИТЫВАТЬ ТАРГЕТ ПРИ ФИЛЬТРАЦИИ ПРИЗНАКОВ\n",
    "target_in_feats = select_model.get_support()[CONTEXT_WINDOW[0]*len(target_labels):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  4.4min remaining:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9705601881898674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.31      0.44      0.36      2139\n",
      "          I       0.20      0.26      0.22      2844\n",
      "          L       0.25      0.36      0.29      2139\n",
      "          O       0.99      0.98      0.99    419119\n",
      "          U       0.31      0.69      0.43       562\n",
      "\n",
      "avg / total       0.98      0.97      0.97    426803\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "cv_logit = cross_val_predict(logit, selected_train, y_train, cv = skf, verbose = 5, n_jobs=4)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_train, cv_logit))\n",
    "print(classification_report(y_train, cv_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9592356243679604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.35      0.37      0.36       356\n",
      "          I       0.19      0.22      0.20       792\n",
      "          L       0.32      0.35      0.33       356\n",
      "          O       0.98      0.98      0.98     55845\n",
      "          U       0.07      0.60      0.13         5\n",
      "\n",
      "avg / total       0.96      0.96      0.96     57354\n",
      "\n",
      "Accuracy:\n",
      "0.9677790563866513\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.35      0.36      0.36       356\n",
      "          I       0.36      0.19      0.25       792\n",
      "          L       0.32      0.33      0.32       356\n",
      "          O       0.98      0.99      0.98     55845\n",
      "          U       0.07      0.60      0.13         5\n",
      "\n",
      "avg / total       0.96      0.97      0.97     57354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = CustomLogisticRegression(random_state=seed,class_weight='balanced')\n",
    "logit.fit(selected_train, y_train)\n",
    "test_logit = logit.predict(selected_test)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))\n",
    "\n",
    "test_logit = rule_correction(test_logit)\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, test_logit))\n",
    "print(classification_report(y_test, test_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Записать результаты в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('results.csv','w',encoding='utf-8-sig') as f:\n",
    "    f.write('true;pred_corr\\n')\n",
    "    f.write('\\n'.join([';'.join(x) for x in zip(y_test,test_logit)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('X_test.csv',encoding='utf-8-sig',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## сделать лейблы бинарными и посмотреть качество "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_backup = deepcopy(y_test)\n",
    "logit_test_backup = deepcopy(test_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logit = deepcopy(logit_test_backup)\n",
    "y_test = deepcopy(y_test_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logit = [1 if i != 'O' else 0 for i in test_logit]\n",
    "y_test[y_test != 'O'] = 1\n",
    "y_test[y_test == 'O'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9684590438330369\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98     55845\n",
      "          1       0.37      0.29      0.33      1509\n",
      "\n",
      "avg / total       0.96      0.97      0.97     57354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:')\n",
    "print(accuracy_score(list(y_test), test_logit))\n",
    "print(classification_report(list(y_test), test_logit))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
